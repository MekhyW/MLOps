{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "93715d0c-b99d-4513-8c70-3a727df17133",
   "metadata": {},
   "source": [
    "# Bank Marketing Dataset - Notebook 03\n",
    "\n",
    "Predicting Term Deposit Suscriptions\n",
    "\n",
    "This notebook demonstrates how to train a model using the notebook's instance (no extra computational resources)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "794724cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls -la"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "885c13be",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls -la data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8e0b408",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install sagemaker ipywidgets --upgrade --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d08d2b1",
   "metadata": {},
   "source": [
    "## Import libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50a8b62e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker, boto3, json\n",
    "import pprint\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "from sagemaker import get_execution_role\n",
    "from sklearn.utils import resample\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sagemaker.debugger import Rule, rule_configs\n",
    "from sagemaker.debugger import DebuggerHookConfig, CollectionConfig\n",
    "from sagemaker.estimator import Estimator\n",
    "from sagemaker.inputs import TrainingInput\n",
    "from sklearn.metrics import roc_curve, roc_auc_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4909cfe",
   "metadata": {},
   "source": [
    "## Define preproc functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2983819e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rebalance(data):\n",
    "    \"\"\"\n",
    "    Resample data to keep balance between target classes.\n",
    "\n",
    "    The function uses the resample function to downsample the minority class to match the majority class.\n",
    "\n",
    "    Args:\n",
    "        data (pd.DataFrame): DataFrame\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame): balanced DataFrame\n",
    "    \"\"\"\n",
    "    churn_0 = data[data[\"Exited\"] == 0]\n",
    "    churn_1 = data[data[\"Exited\"] == 1]\n",
    "    if len(churn_0) > len(churn_1):\n",
    "        churn_maj = churn_0\n",
    "        churn_min = churn_1\n",
    "    else:\n",
    "        churn_maj = churn_1\n",
    "        churn_min = churn_0\n",
    "    churn_maj_downsample = resample(\n",
    "        churn_maj, n_samples=len(churn_min), replace=False, random_state=1234\n",
    "    )\n",
    "\n",
    "    return pd.concat([churn_maj_downsample, churn_min])\n",
    "\n",
    "\n",
    "def preprocess(df):\n",
    "    \"\"\"\n",
    "    Preprocess and split data into training and test sets.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): DataFrame with features and target variables\n",
    "\n",
    "    Returns:\n",
    "        ColumnTransformer: ColumnTransformer with scalers and encoders\n",
    "        pd.DataFrame: training data with transformed features\n",
    "        pd.DataFrame: test data with transformed features\n",
    "    \"\"\"\n",
    "    filter_feat = [\n",
    "        \"Exited\",\n",
    "        \"CreditScore\",\n",
    "        \"Geography\",\n",
    "        \"Gender\",\n",
    "        \"Age\",\n",
    "        \"Tenure\",\n",
    "        \"Balance\",\n",
    "        \"NumOfProducts\",\n",
    "        \"HasCrCard\",\n",
    "        \"IsActiveMember\",\n",
    "        \"EstimatedSalary\",\n",
    "    ]\n",
    "    cat_cols = [\"Geography\", \"Gender\"]\n",
    "    num_cols = [\n",
    "        \"CreditScore\",\n",
    "        \"Age\",\n",
    "        \"Tenure\",\n",
    "        \"Balance\",\n",
    "        \"NumOfProducts\",\n",
    "        \"HasCrCard\",\n",
    "        \"IsActiveMember\",\n",
    "        \"EstimatedSalary\",\n",
    "    ]\n",
    "    data = df.loc[:, filter_feat]\n",
    "    data_bal = rebalance(data=data)\n",
    "\n",
    "    df_train, df_test = train_test_split(\n",
    "        data_bal, test_size=0.3, random_state=1912\n",
    "    )\n",
    "    col_transf = make_column_transformer(\n",
    "        (StandardScaler(), num_cols),\n",
    "        (OneHotEncoder(handle_unknown=\"ignore\", drop=\"first\", sparse_output=False), cat_cols),\n",
    "        remainder=\"passthrough\",\n",
    "        verbose_feature_names_out=False\n",
    "    ).set_output(transform='pandas')\n",
    "\n",
    "    df_train = col_transf.fit_transform(df_train)\n",
    "    df_train = df_train\n",
    "\n",
    "    df_test = col_transf.transform(df_test)\n",
    "    \n",
    "    cols = df_train.columns.tolist()\n",
    "    cols = [cols[-1]] + cols[:-1]\n",
    "\n",
    "    # Reorder the columns in the DataFrame\n",
    "    df_train = df_train[cols]\n",
    "    df_test = df_test[cols]\n",
    "\n",
    "    return col_transf, df_train, df_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38097ed7",
   "metadata": {},
   "source": [
    "## Start coding!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c9a6313",
   "metadata": {},
   "outputs": [],
   "source": [
    "aws_role = get_execution_role()\n",
    "aws_region = boto3.Session().region_name\n",
    "sess = sagemaker.Session()\n",
    "\n",
    "print(f\"Role is: {aws_role}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f08cebd4",
   "metadata": {},
   "source": [
    "## Configure Bucket to export results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a91030b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket = \"sagemaker-mlops-out-YOUR_INSPER_USERNAME\"\n",
    "bucket_path = f\"https://s3-{aws_region}.amazonaws.com/{bucket}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d316000",
   "metadata": {},
   "source": [
    "Create a bucket to store your experiment results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b27a13fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "s3 = boto3.client(\"s3\")\n",
    "\n",
    "s3.create_bucket(\n",
    "    Bucket=bucket,\n",
    "    CreateBucketConfiguration={\"LocationConstraint\": aws_region},\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "613eceac",
   "metadata": {},
   "source": [
    "## Open Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8da60a66",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/Churn_Modelling.csv\")\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01746c6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "col_transf, df_train, df_test = preprocess(df)\n",
    "df_train.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa27413b",
   "metadata": {},
   "source": [
    "Export to parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44779846",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.to_parquet(\"churn_train.parquet\")\n",
    "df_test.to_parquet(\"churn_test.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84fba0d5",
   "metadata": {},
   "source": [
    "And export to `data` inside the S3 bucket:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13fe9cac",
   "metadata": {},
   "outputs": [],
   "source": [
    "sagemaker.Session().upload_data(\n",
    "    \"churn_train.parquet\", bucket=bucket, key_prefix=\"data/train\"\n",
    ")\n",
    "\n",
    "sagemaker.Session().upload_data(\n",
    "    \"churn_test.parquet\", bucket=bucket, key_prefix=\"data/test\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac92f534",
   "metadata": {},
   "source": [
    "## Create Sagemaker Training Job\n",
    "\n",
    "\n",
    "A SageMaker training job is a unit of work in Amazon SageMaker. It involves the process of training an ML model using a specified dataset and a chosen algorithm or framework.\n",
    "\n",
    "When you initiate a training job in SageMaker, you provide the necessary configuration, including the location of the training data, the ML algorithm or framework to be used, the compute resources required, and any hyperparameter settings. SageMaker then **provisions the necessary infrastructure**, such as instances or GPU-accelerated instances, to perform the training.\n",
    "\n",
    "During the training job, the ML model is trained by iteratively processing the training data and adjusting the model's parameters to minimize the defined loss or maximize the defined objective. The training progress, including metrics and logs, is captured and can be monitored in real-time.\n",
    "\n",
    "Once the training job is completed, the trained model is saved in a specified output location, such as Amazon S3. This trained model can then be used for inference or deployed to make predictions on new data.\n",
    "\n",
    "In summary, a SageMaker training job encapsulates the process of training an ML model by providing the necessary configuration, managing the required compute resources, and capturing the resulting trained model for further use. It enables efficient and scalable model training in the cloud.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c873df0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sagemaker client\n",
    "client = boto3.client(\"sagemaker\", region_name=aws_region)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32e8a058",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure data source\n",
    "train_data_uri = f\"s3://{bucket}/data/train/churn_train.parquet\"\n",
    "val_data_uri = f\"s3://{bucket}/data/test/churn_test.parquet\"\n",
    "\n",
    "train_input = TrainingInput(train_data_uri, content_type=\"application/x-parquet\")\n",
    "val_input = TrainingInput(val_data_uri, content_type=\"application/x-parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21ea5cc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get xgboost image\n",
    "image = sagemaker.image_uris.retrieve(\"xgboost\", aws_region, \"1.7-1\")\n",
    "image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52173880",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure instance, output path and model name\n",
    "estimator_output_path = f\"s3://{bucket}/training_jobs\"\n",
    "train_instance_count = 1\n",
    "train_instance_type = \"ml.m5.large\"\n",
    "save_interval = 2\n",
    "model_name = \"churn-new-model-{}\".format(datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
    "\n",
    "hyperparameters = {\n",
    "    \"max_depth\": \"4\",\n",
    "    \"eta\": \"0.2\",\n",
    "    \"objective\": \"binary:logistic\",\n",
    "    \"num_round\": \"100\",\n",
    "}\n",
    "\n",
    "# Create estimator\n",
    "xgb_estimator = Estimator(\n",
    "    role=aws_role,\n",
    "    instance_count=train_instance_count,\n",
    "    instance_type=train_instance_type,\n",
    "    image_uri=image,\n",
    "    hyperparameters=hyperparameters,\n",
    "    output_path=estimator_output_path,\n",
    "    debugger_hook_config=DebuggerHookConfig(\n",
    "        s3_output_path=estimator_output_path + \"/debugger\",\n",
    "        collection_configs=[\n",
    "            CollectionConfig(name=\"metrics\", parameters={\"save_interval\": str(save_interval)}),\n",
    "            CollectionConfig(\n",
    "                name=\"feature_importance\", parameters={\"save_interval\": str(save_interval)}\n",
    "            ),\n",
    "            CollectionConfig(name=\"full_shap\", parameters={\"save_interval\": str(save_interval)}),\n",
    "            CollectionConfig(name=\"average_shap\", parameters={\"save_interval\": str(save_interval)}),\n",
    "        ],\n",
    "    ),\n",
    "    rules=[\n",
    "        Rule.sagemaker(\n",
    "            rule_configs.loss_not_decreasing(),\n",
    "            rule_parameters={\n",
    "                \"collection_names\": \"metrics\",\n",
    "                \"num_steps\": str(save_interval * 2),\n",
    "            },\n",
    "        )\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc2b86a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.list_training_jobs(\n",
    "    NameContains=model_name, StatusEquals=\"Completed\", SortBy=\"CreationTime\", SortOrder=\"Descending\"\n",
    ")\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3a1f616",
   "metadata": {},
   "source": [
    "Now we train the model with:\n",
    "\n",
    "<div class=\"alert alert-info\">\n",
    "\n",
    "While the model trains, access the AWS console (ask the teacher for the URL and credentials) and check the left side menu **Training / Training jobs** in Sagemaker.\n",
    "\n",
    "\n",
    "Take the opportunity to also see the option **Notebook / Notebook instances**.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3013f31d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "train_model = True  # True if training a new model, False if wanting to use an existing estimator once you've already trained\n",
    "\n",
    "if train_model:\n",
    "    print(\"Training the model\")\n",
    "    xgb_estimator.fit(inputs={\"train\": train_input, \"validation\": val_input}, job_name=model_name)\n",
    "    s3_debugger_output_path = xgb_estimator.latest_job_debugger_artifacts_path()\n",
    "elif len(response[\"TrainingJobSummaries\"]) > 0:\n",
    "    training_job_name = response[\"TrainingJobSummaries\"][0][\"TrainingJobName\"]\n",
    "    xgb_estimator = Estimator.attach(training_job_name)\n",
    "    s3_debugger_output_path = xgb_estimator.latest_job_debugger_artifacts_path()\n",
    "else:\n",
    "    print(\"No existing estimator found. You'll need to run as train = True\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "917fd14c",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_job_name = xgb_estimator.latest_training_job.job_name\n",
    "print(training_job_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a6a3018",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_job_info = client.describe_training_job(TrainingJobName=training_job_name)\n",
    "pprint.pprint(f\"{training_job_info}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82bbf79d",
   "metadata": {},
   "source": [
    "### Deploy Model\n",
    "\n",
    "<div class=\"alert alert-info\">\n",
    "\n",
    "While the model is deployed, access the AWS console (ask the teacher for the URL and credentials) and check the left side menu:\n",
    "    \n",
    "- **Inference / Models** in Sagemaker\n",
    "- **Inference / Endpoints** in Sagemaker\n",
    "- `sagemaker-mlops-out-YOUR_INSPER_USERNAME` bucket in S3.\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a21eba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aa164b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint_name = \"churn-model-endpoint-{}\".format(datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
    "print(endpoint_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dac24268",
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint_list = client.list_endpoints(\n",
    "    SortBy=\"CreationTime\",\n",
    "    SortOrder=\"Descending\",\n",
    "    NameContains=endpoint_name,\n",
    "    StatusEquals=\"InService\",\n",
    ")\n",
    "endpoint_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97597beb",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "if len(endpoint_list[\"Endpoints\"]) > 0:\n",
    "    print(f\"Using existing endpoint: {endpoint_list['Endpoints'][0]['EndpointName']}\")\n",
    "else:\n",
    "    # deploy endpoint for model if it doesn't already exist\n",
    "    xgb_estimator.deploy(\n",
    "        initial_instance_count=1, instance_type=\"ml.m4.xlarge\", endpoint_name=endpoint_name\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaf152e6",
   "metadata": {},
   "source": [
    "#### Create predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8595f119",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor = sagemaker.predictor.Predictor(\n",
    "    endpoint_name=endpoint_name, sagemaker_session=sess\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "369b08c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_input(df_inference):\n",
    "    return [\n",
    "        \",\".join([str(i) for i in row])\n",
    "        for row in df_inference.drop(\"Exited\", axis=1).values\n",
    "    ]\n",
    "\n",
    "def get_predictions(data_inputs):\n",
    "    predictions = []\n",
    "    for data_input in data_inputs:\n",
    "        results = predictor.predict(data_input, initial_args={\"ContentType\": \"text/csv\"})\n",
    "        prediction = json.loads(results)\n",
    "        predictions.append(prediction)\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4c4cbb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To simulate new data, predict a sample of df_test\n",
    "df_inference = df_test.sample(3, random_state=42)\n",
    "\n",
    "data_inputs = get_data_input(df_inference)\n",
    "data_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6b55ff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = get_predictions(data_inputs)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3b7a43e",
   "metadata": {},
   "source": [
    "### Plot ROC Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5c2fd44",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_inference = df_test\n",
    "\n",
    "data_inputs = get_data_input(df_inference)\n",
    "predictions = get_predictions(data_inputs)\n",
    "y_true = df_inference[\"Exited\"]\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(y_true, predictions)\n",
    "\n",
    "# Calculate the Area Under the ROC Curve (AUC)\n",
    "auc = roc_auc_score(y_true, predictions)\n",
    "\n",
    "plt.plot(fpr, tpr, label=f'ROC curve (AUC = {auc:.2f})')\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}